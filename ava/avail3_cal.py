import re
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from datetime import datetime, timedelta
import os
from dateutil.relativedelta import relativedelta
from pandas import Timestamp
from io import BytesIO
from io import StringIO
from babel.dates import format_date

# Set page
st.set_page_config(page_title='Dashboard‚Äç', page_icon=':bar_chart:', layout="wide", initial_sidebar_state="expanded", menu_items=None)
with open('./css/style.css')as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html = True)
    


#source_csv_event = "D:/ML/scada/ava/source_csv/S1-AVR-LBS-RCS-REC_VSP_JAN-MAR2025.csv"
#source_csv_event = "D:/ML/scada/ava/source_csv/availability_data_‡∏°.‡∏Ñ._2025.csv"
source_csv_remote = "D:/ML/scada/ava/source_excel/excel file jan-mar/RemoteUnit_01052025_filtered.csv"
source_excel = "./source_excel/S1-REC_JAN-MAR2025.xlsx"
event_path_parquet = "./Output_file/S1-REC-020X-021X-0220.parquet"
remote_path_parquet = "./Output_file/combined_output_rtu.parquet"
cols_event=["Field change time", "Message", "Device"]
normal_state = "Online"
abnormal_states = ["Initializing", "Telemetry Failure", "Connecting", "Offline"]
state = ["Online", "Initializing", "Telemetry Failure", "Connecting", "Offline"]
option_menu = ['‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå','%‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô', '%‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£', '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£']
bins_eva = [0, 80, 90, 100]
labels_eva = ["0 <= Availability (%) <= 80", "80 < Availability (%) <= 90", "90 < Availability (%) <= 100"] 


@st.cache_data
def load_data_xls(uploaded_file):
    usecols1 = ["Name", "State", "Description", "Substation"]
    usecols2=["Field change time", "Message", "Device"]
    df = pd.read_excel(uploaded_file, usecols=usecols2)
    #df = df[df["Substation"] == "S1 FRTU"]
    #df.rename(columns={"Name": "Device"}, inplace=True)
    return df

@st.cache_data
def load_parquet(path):
    return pd.read_parquet(path, engine="pyarrow")

@st.cache_data   
def load_data_csv(file_path):
    df = pd.read_csv(file_path)
    return df

def merge_data(df1,df2,flag):
    df1.rename(columns={"Name": "Device"}, inplace=True)
    if flag == 'substation':
        df1 = df1[
            ((df1["‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á"] == "‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤")) |
            ((df1["‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á"] == "‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤") & df1["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå"].isin(["SPP-Substation", "VSPP-Substation"]))
            ]
    else:
        df1 = df1[df1["Substation"] == "S1 FRTU"]
    
    df_filters = df1.merge(df2, on="Device", how="outer", suffixes=("_old", ""))
    #df_filters = df_filters.drop(['Substation'], axis=1, inplace=True) # ‡∏•‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡πá‡πÑ‡∏î‡πâ
    df_filters = df_filters.drop(columns=["Substation","‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô/‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"], errors='ignore')  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ô‡∏µ‡πâ
    df_filters = df_filters[[
    "Device", "Description", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà", "‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏ü‡πâ‡∏≤", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á", "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå", 
    "Availability (%)", 
    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Online", "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Online (seconds)", 
    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Connecting","‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Connecting (seconds)",
    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Initializing", "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Initializing (seconds)",
    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Telemetry Failure", "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Telemetry Failure (seconds)",
    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Offline", "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Offline (seconds)" 
]]
    return df_filters

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ Previous State ‡πÅ‡∏•‡∏∞ New State ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏à‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
def extract_states(message):
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô "Remote Unit is now in expected state (Online)."
    if "Remote Unit is now in expected state (Online)." in str(message):
        return (None, None)  # ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤
    match = re.search(r"Remote unit state changed from (.+?) to (.+)", str(message))
    return (match.group(1), match.group(2).strip(".")) if match else (None, None)

def split_state(df):
    #df = df.drop(columns=["#"], errors="ignore")
    #df["Field change time"] = pd.to_datetime(df["Field change time"], format="%d/%m/%Y %I:%M:%S.%f %p", errors='coerce')
    df = df.dropna(subset=["Field change time"])  # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ NaT ‡πÉ‡∏ô "Field change time"
    #df_filtered = df[(df['Field change time'].between(startdate, enddate))]
    df_filtered = df[['Field change time', 'Message', 'Device']].sort_values("Field change time").reset_index(drop=True)
    #df_filtered['Adjusted Duration (seconds)'] = df_filtered['Adjusted Duration (seconds)'].fillna(0)
    df_filtered[["Previous State", "New State"]] = df_filtered["Message"].apply(lambda x: pd.Series(extract_states(x))) # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å Previous State ‡πÅ‡∏•‡∏∞ New State
    #df_filtered['Previous State'], df_filtered['New State'] = zip(*df_filtered['Message'].apply(extract_states))
    df_filtered= df_filtered.dropna(subset=["Previous State", "New State"]).reset_index(drop=True) # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    return df_filtered

def sort_state_chain(df):
    """‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ Field change time ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ New State ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡∏ö‡∏ô = Previous State ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"""
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
    grouped = df.groupby("Field change time")
    result = []

    for group_time, group_df in grouped:
        if len(group_df) == 1:
            result.append(group_df)
            continue

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á map ‡∏Ç‡∏≠‡∏á Previous -> Row
        state_map = {row["Previous State"]: row for _, row in group_df.iterrows()}
        new_states = set(group_df["New State"])
        prev_states = set(group_df["Previous State"])

        # ‡∏´‡∏≤ "‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô" ‡∏Ñ‡∏∑‡∏≠ Previous State ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà New State ‡∏Ç‡∏≠‡∏á‡πÉ‡∏Ñ‡∏£‡πÄ‡∏•‡∏¢
        start_candidates = list(prev_states - new_states)

        if not start_candidates:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡πÄ‡∏ä‡πà‡∏ô loop ‡∏´‡∏£‡∏∑‡∏≠ incomplete), ‡πÉ‡∏ä‡πâ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô
            sorted_group = group_df
        else:
            current_state = start_candidates[0]
            rows = []
            visited = set()

            while current_state in state_map and current_state not in visited:
                row = state_map[current_state]
                rows.append(row)
                visited.add(current_state)
                current_state = row["New State"]

            sorted_group = pd.DataFrame(rows)

        result.append(sorted_group)

    # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡πâ‡∏ß
    return pd.concat(result).reset_index(drop=True)

def adjust_stateandtime(df, startdate, enddate):
    if df.empty:
        return df  # ‡∏ñ‡πâ‡∏≤ DataFrame ‡∏ß‡πà‡∏≤‡∏á ‡πÉ‡∏´‡πâ return ‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
    df["Next Change Time"] = df["Field change time"].shift(-1) # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
    # ‚úÖ **‡πÄ‡∏û‡∏¥‡πà‡∏° State ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô**
    first_change_time = df["Field change time"].iloc[0]
    if first_change_time > startdate:
        first_state = df["Previous State"].iloc[0]
        new_row = pd.DataFrame({
            "Device": df["Device"].iloc[0],
            "Field change time": [startdate],
            "Previous State": [first_state],
            "New State": [first_state],
            "Next Change Time": [first_change_time]
        })
        #df = pd.concat([new_row, df], ignore_index=True).reindex(columns=df.columns)
        df = pd.concat([new_row, df], ignore_index=True)
    # ‚úÖ **‡πÄ‡∏û‡∏¥‡πà‡∏° State ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô**
    if len(df) > 1:  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô IndexError ‡∏à‡∏≤‡∏Å iloc[-2]
        last_change_time = df["Next Change Time"].iloc[-2]
        if pd.notna(last_change_time) and last_change_time < enddate:
            last_state = df["New State"].iloc[-1]
            new_row = pd.DataFrame({
                "Device": df["Device"].iloc[-1],
                "Field change time": [last_change_time],
                "Previous State": [last_state],
                "New State": [last_state],
                "Next Change Time": [enddate]
            })
            #df = pd.concat([df, new_row], ignore_index=True).reindex(columns=df.columns)
            df = pd.concat([new_row, df], ignore_index=True)
    # ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    df["Adjusted Start"] = df["Field change time"].clip(lower=startdate, upper=enddate)
    df["Adjusted End"] = df["Next Change Time"].clip(lower=startdate, upper=enddate)
    df["Adjusted Start"] = pd.to_datetime(df["Adjusted Start"], errors='coerce')
    df["Adjusted End"] = pd.to_datetime(df["Adjusted End"], errors='coerce')
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ State (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
    df["Adjusted Duration (seconds)"] = (df["Adjusted End"] - df["Adjusted Start"]).dt.total_seconds()
    df = df.dropna(subset=["Adjusted Duration (seconds)"])

    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    df = df[(df["Adjusted Start"] >= startdate) & (df["Adjusted End"] <= enddate)]

    # ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤ start_time ‡πÅ‡∏•‡∏∞ end_time ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß
    df["Start Time Filter"] = startdate
    df["End Time Filter"] = enddate
    df[["Days", "Hours", "Minutes", "Seconds"]] = df["Adjusted Duration (seconds)"].apply(
        lambda x: pd.Series(split_duration(x), index=["Days", "Hours", "Minutes", "Seconds"]))
    df["Formatted Duration"] = df.apply(format_duration, axis=1)
    #df["Month_stamp"] = pd.to_datetime(df["Field change time"], format="%d/%m/%Y %I:%M:%S.%f", errors='coerce').dt.strftime('%Y-%m')
    return df

# ‚úÖ **‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ**
def split_duration(seconds):
    days = int(seconds // (24 * 3600))
    hours = int((seconds % (24 * 3600)) // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = int(seconds % 60)
    return days, hours, minutes, seconds

# ‚úÖ **‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°**
def format_duration(row):
    parts = []
    if row["Days"] > 0:
        parts.append(f"{row['Days']} ‡∏ß‡∏±‡∏ô")
    if row["Hours"] > 0:
        parts.append(f"{row['Hours']} ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á")
    if row["Minutes"] > 0:
        parts.append(f"{row['Minutes']} ‡∏ô‡∏≤‡∏ó‡∏µ")
    if row["Seconds"] > 0:
        parts.append(f"{row['Seconds']} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    return " ".join(parts) if parts else "0 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ"

@st.cache_data 
#@st.cache
def calculate_state_summary(df_filtered):
    # ‚úÖ **‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞ State**
    state_duration_summary = df_filtered.groupby("New State", dropna=True)["Adjusted Duration (seconds)"].sum().reset_index()
    state_duration_summary[["Days", "Hours", "Minutes", "Seconds"]] = state_duration_summary["Adjusted Duration (seconds)"].apply(lambda x: pd.Series(split_duration(x)))
    state_duration_summary["Formatted Duration"] = state_duration_summary.apply(format_duration, axis=1)
    state_duration_summary.rename(columns={"New State": "State"}, inplace=True)
    # ‚úÖ **‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Availability (%)**
    normal_duration = df_filtered[df_filtered["New State"] == normal_state]["Adjusted Duration (seconds)"].sum()
    abnormal_duration = df_filtered[df_filtered["New State"].isin(abnormal_states)]["Adjusted Duration (seconds)"].sum()
    total_duration = df_filtered["Adjusted Duration (seconds)"].sum()
    if total_duration > 0:
        normal_percentage = (normal_duration / total_duration) * 100
        abnormal_percentage = (abnormal_duration / total_duration) * 100
        # ‚úÖ **‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Availability (%) ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ State**
        state_duration_summary["Availability (%)"] = (state_duration_summary["Adjusted Duration (seconds)"] / total_duration) * 100
    else:
        normal_percentage = 0
        abnormal_percentage = 0
        state_duration_summary["Availability (%)"] = 0
    return state_duration_summary

def calculate_device_availability(df_filtered):
    # ‚úÖ **‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Availability (%) ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Device**
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Device
    device_total_duration = df_filtered.groupby("Device")["Adjusted Duration (seconds)"].sum().reset_index()
    device_total_duration.columns = ["Device", "Total Duration (seconds)"]
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà Device ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏Å‡∏ï‡∏¥
    device_online_duration = df_filtered[df_filtered["New State"] == normal_state].groupby("Device")["Adjusted Duration (seconds)"].sum().reset_index()
    device_online_duration.columns = ["Device", "Online Duration (seconds)"]
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
    device_availability = device_total_duration.merge(device_online_duration, on="Device", how="left").fillna(0)
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Availability (%)
    device_availability["Availability (%)"] = (device_availability["Online Duration (seconds)"] / device_availability["Total Duration (seconds)"]) * 100
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏õ‡πá‡∏ô ‡∏ß‡∏±‡∏ô ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
    device_availability[["Online Days", "Online Hours", "Online Minutes", "Online Seconds"]] = device_availability["Online Duration (seconds)"].apply(
        lambda x: pd.Series(split_duration(x)))
    device_availability[["Total Days", "Total Hours", "Total Minutes", "Total Seconds"]] = device_availability["Total Duration (seconds)"].apply(
        lambda x: pd.Series(split_duration(x)))
    return device_availability

@st.cache_data 
#@st.cache
def calculate_device_count(df_filtered,device_availability):
    # ‚úÖ **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î State ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Device**
    #device_availability = calculate_device_availability(df_filtered)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ State
    state_count = df_filtered[df_filtered["New State"].isin(state)].groupby(["Device", "New State"]).size().unstack(fill_value=0)
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ State
    state_duration = df_filtered[df_filtered["New State"].isin(state)].groupby(["Device", "New State"])["Adjusted Duration (seconds)"].sum().unstack(fill_value=0)
    # ‡∏£‡∏ß‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ State
    summary_df = state_count.merge(state_duration, left_index=True, right_index=True, suffixes=(" Count", " Duration (seconds)"))
    # ‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    summary_df = summary_df.reindex(columns=[
        "Initializing Count", "Initializing Duration (seconds)",
        "Telemetry Failure Count", "Telemetry Failure Duration (seconds)",
        "Connecting Count", "Connecting Duration (seconds)",
        "Offline Count", "Offline Duration (seconds)",
        "Online Count"
    ])
    # ‚úÖ **‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ "Device" ‡πÄ‡∏õ‡πá‡∏ô key**
    merged_df = pd.merge(device_availability, summary_df, on="Device", how="left")
    # ‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    merged_df = merged_df[[
        "Device", "Availability (%)",
        "Online Count", "Online Duration (seconds)",
        "Connecting Count", "Connecting Duration (seconds)",
        "Initializing Count", "Initializing Duration (seconds)",
        "Telemetry Failure Count", "Telemetry Failure Duration (seconds)",
        "Offline Count", "Offline Duration (seconds)" 
    ]]
    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ 
    merged_df = merged_df.rename(columns={
        "Online Count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Online", 
        "Online Duration (seconds)": "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Online (seconds)",
        "Connecting Count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Connecting",
        "Connecting Duration (seconds)": "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Connecting (seconds)",
        "Initializing Count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Initializing",
        "Initializing Duration (seconds)": "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Initializing (seconds)",
        "Telemetry Failure Count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Telemetry Failure",
        "Telemetry Failure Duration (seconds)": "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Telemetry Failure (seconds)",
        "Offline Count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Offline",
        "Offline Duration (seconds)": "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Offline (seconds)"
    })
    return merged_df, state_count, state_duration

def plot(df):
    # ‚úÖ **BarChart**
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡∏≠‡∏á Availability (%) ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏•‡∏∞ 10%
    bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
    labels = [f"{bins[i]}-{bins[i+1]}" for i in range(len(bins)-1)]  # ["0-10", "10-20", ..., "90-100"]
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Availability (%) ‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    df_plot = df.copy()  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô SettingWithCopyWarning
    df_plot.loc[:, "Availability Range"] = pd.cut(df_plot["Availability (%)"], bins=bins, labels=labels, right=True, include_lowest=True)
    # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á Availability (%)
    availability_counts = df_plot["Availability Range"].value_counts().reindex(labels, fill_value=0).reset_index()
    availability_counts.columns = ["Availability Range", "Device Count"]
    total_device_count = availability_counts["Device Count"].sum()
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Histogram ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ px.bar() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° bin edges ‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á
    fig = px.bar(
        availability_counts,
        x="Availability Range",
        y="Device Count",
        title=f"Plot ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {total_device_count} Device ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á Availability (%)",
        labels={"Availability Range": "Availability (%)", "Device Count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device"},
        text_auto=True  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü
    )
    # ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏≤‡∏ü
    fig.update_layout(
        xaxis_title="Availability (%)",
        yaxis_title="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device",
        title_font_size=20,
        xaxis_tickangle=-45,  # ‡∏´‡∏°‡∏∏‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏Å‡∏ô X"
        bargap=0.005
    )
    return fig

def evaluate(df,bins,labels):
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"
    df["‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"] = pd.cut(df["Availability (%)"], bins=bins, labels=labels, right=True)
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
    def evaluate_result(row):
        if row["‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"] == "90 < Availability (%) <= 100":
            return "‚úÖ ‡πÑ‡∏°‡πà‡πÅ‡∏Æ‡∏á‡∏Ñ‡πå"
        elif row["‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"] == "80 < Availability (%) <= 90":
            return "‚ö†Ô∏è ‡∏ó‡∏£‡∏á‡πÜ"
        else:
            return "‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏≠‡∏ô"
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"
    df["‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"] = df.apply(evaluate_result, axis=1)
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Å‡∏ì‡∏ë‡πå
    summary_df = df["‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"].value_counts().reset_index()
    summary_df.columns = ["‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device"]
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ "‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô" ‡πÅ‡∏•‡∏∞ "‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"
    summary_df = df.groupby(["‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", "‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"]).size().reset_index(name="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device")
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device" ‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏≠‡∏≠‡∏Å
    summary_df = summary_df[summary_df["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device"] > 0]
    # ‡∏•‡∏ö index ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å summary_df
    summary_df = summary_df.reset_index(drop=True)
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Availability (%) ‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    df["Availability Range"] = pd.cut(
        df["Availability (%)"], bins=bins, labels=labels, right=True
    )
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á Device
    total_devices = summary_df["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device"].sum()
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á
    summary_df["‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå (%)"] = (summary_df["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device"] / total_devices) * 100
    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° 2 ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
    #summary_df["‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå (%)"] = summary_df["‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå (%)"].map("{:.2f}%".format)
    summary_df["‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå (%)"] = summary_df["‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå (%)"].round(2)
    fig1 = px.bar(
        summary_df,
        x="‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô",
        y="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device",
        color="‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô",
        text="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device",
        barmode="group",
        title="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device ‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô",
    )
    # ‚úÖ Pie Chart ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
    fig2 = px.pie(
        summary_df,
        names="‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô",
        values="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Device",
        title="‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô",
        hole=0.4
    )
    fig2.update_traces(textinfo='percent+label')
    #st.plotly_chart(fig2, use_container_width=True)
    return df, summary_df, fig1, fig2

def add_value(df_filters):
    #new_columns = ["Availability (%)","‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Initializing","‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Initializing (seconds)","‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Telemetry Failure","‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Telemetry Failure (seconds)","‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Connecting","‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Connecting (seconds)"]
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å
    #df_remote.drop(columns=[col for col in df_remote.columns if col.endswith("_old")], inplace=True)
    df_add_value = df_filters.fillna({
        "Availability (%)": 100.00,
        "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Online": 0, 
        "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Online (seconds)": 0,
        "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Connecting": 0,
        "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Connecting (seconds)": 0,
        "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Initializing": 0,
        "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Initializing (seconds)": 0,
        "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Telemetry Failure": 0,
        "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Telemetry Failure (seconds)": 0,
        "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á Offline": 0,
        "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ Offline (seconds)": 0
        #"‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô": "90 < Availability (%) <= 100",
        #"‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô": "‚úÖ ‡πÑ‡∏°‡πà‡πÅ‡∏Æ‡∏á‡∏Ñ‡πå",
        #"Availability Range": "90 < Availability (%) <= 100"
    })
    return df_add_value

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡πâ session_state
def initial_date(df):
    df["Field change time"] = pd.to_datetime(df["Field change time"], format="%d/%m/%Y %I:%M:%S.%f %p", errors='coerce')
    if "selected_devices" not in st.session_state:
        st.session_state.selected_devices = "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
    if "start_date" not in st.session_state:
        st.session_state.start_date = df["Field change time"].min().date()
        #st.session_state.start_date = pd.to_datetime("01/01/2024").date()
    if "end_date" not in st.session_state:
        st.session_state.end_date = df["Field change time"].max().date()
        #st.session_state.end_date = pd.to_datetime("31/12/2024").date()
    if "start_time" not in st.session_state:
        st.session_state.start_time = df["Field change time"].min().strftime("%H:%M:%S.%f")[:-3]
        #st.session_state.start_time = pd.to_datetime("00:00:00").strftime("%H:%M:%S")
    if "end_time" not in st.session_state:
        st.session_state.end_time = df["Field change time"].max().strftime("%H:%M:%S.%f")[:-3]
        #st.session_state.end_time = pd.to_datetime("00:00:00").strftime("%H:%M:%S")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Callback ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡πà‡∏≤ session_state
def update_dates():
    st.session_state.start_date = st.session_state.start_date
    st.session_state.end_date = st.session_state.end_date
    st.session_state.start_time = st.session_state.start_time
    st.session_state.end_time = st.session_state.end_time

def add_peroid(df, startdate, enddate):
    locale_setting = "th_TH"

    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô ‡∏°.‡∏Ñ., ‡∏Å.‡∏û.
    start_month = format_date(startdate, format="LLL", locale=locale_setting)
    end_month = format_date(enddate, format="LLL", locale=locale_setting)
    
    start_year = startdate.year
    end_year = enddate.year

    if start_year == end_year:
        if startdate.month == enddate.month:
            period_label = f"{start_month} {start_year}"
        else:
            period_label = f"{start_month} - {end_month} {start_year}"
    else:
        period_label = f"{start_month} {start_year} - {end_month} {end_year}"
    
    df["Availability Period"] = period_label
    return df, period_label

def main():
    #st.title("üìä ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ö‡∏ô‡∏£‡∏∞‡∏ö‡∏ö SCADA/TDMS")
    #st.markdown("---------")
    #st.sidebar.header("Menu:")
    #menu_select = st.sidebar.radio(label="", options = option_menu)
    #st.sidebar.markdown("---------")
    
    #st.header("üìä %‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ‡πÅ‡∏•‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏Ø")
    #df_event = load_parquet(event_path_parquet)
    #uploaded_file = st.file_uploader("Upload an Excel file", type=["xlsx","csv"])
    uploaded_file = st.file_uploader("üì• ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏´‡∏£‡∏∑‡∏≠ CSV", type=["xlsx", "csv"])
    if uploaded_file:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
            st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        else:
            st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name} ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    
        df_event = df.copy()
        #df_event = load_data_csv(source_csv_event)
        df_remote = load_data_csv(source_csv_remote)
        df_remote_sub = df_remote.copy()
            #df_event = get_as_dataframe(sheet)
            #df_remote = load_parquet(remote_path_parquet)
        if df_event is not None and not df_remote.empty:
            #if df_remote is not None and not df_remote.empty and df_filtered is not None and not df_filtered.empty:
            #sidebar ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ß‡∏•‡∏≤
            
            with st.sidebar:
                
                # ‚úÖ **‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Start Time ‡πÅ‡∏•‡∏∞ End Time**
                #st.info(f"Menu : {menu_select}")
                #st.header("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
                #df_event["Field change time"] = pd.to_datetime(df_event["Field change time"], format="%d/%m/%Y %I:%M:%S.%f", errors='coerce')
                #start_date = st.sidebar.date_input("Start Date", datetime(2025, 1, 1))
                #end_date = st.sidebar.date_input("End Date", datetime(2025, 12, 31))
                # ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ min/max ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î
                min_date = df_event["Field change time"].min()
                max_date = df_event["Field change time"].max()
            """
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏µ-‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                month_range = pd.date_range(min_date, max_date, freq='MS')
                month_options = month_range.strftime('%Y-%m').tolist()
                if month_options:
                    # Sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                    start_month = st.selectbox("üìÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô", month_options, index=0)
                    end_month = st.selectbox("üìÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î", month_options, index=len(month_options)-1)
                    if start_month and end_month:
                        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô datetime
                        start_date = datetime.strptime(start_month, "%Y-%m")
                        end_date = datetime.strptime(end_month, "%Y-%m") + relativedelta(months=1) - timedelta(seconds=1)
                        df_event = df_event[(df_event["Field change time"] >= start_date) & (df_event["Field change time"] <= end_date)]
                    else:
                        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î")
                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô dataset")
                start_date = Timestamp(start_date)
                end_date = Timestamp(end_date)

            #sidebar ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå
            with st.sidebar:
                #st.header("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå")
                # üîπ ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
                device_list = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + list(df_event["Device"].unique())
                selected_devices = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå", device_list, default=["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"])   
                # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
                #df_merged_add = df_merged_add[df_merged_add["Device"].isin(selected_devices)]
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if not selected_devices or "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" in selected_devices:
                    df_event = df_event.copy()  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                else:
                    df_event = df_event[df_event["Device"].isin(selected_devices)]  # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
                st.markdown("---------")
            """
        ###-----Calc-----###
        df_filtered = split_state(df_event)
        df_filtered = sort_state_chain(df_filtered)
        #initial_date(df_filtered)
        df_filtered = adjust_stateandtime(df_filtered, min_date, max_date)
        state_summary = calculate_state_summary(df_filtered) #Avail ‡πÅ‡∏ï‡πà‡∏•‡∏∞ state
        device_availability = calculate_device_availability(df_filtered)
        df_merged, state_count, state_duration = calculate_device_count(df_filtered,device_availability)
        #mode_select = st.radio("Sub or Frtu", options=["substation","frtu"])
        #if mode_select == 'substation':
        #    flag = 'substation'
        #else:
        #    flag = 'frtu'
        flag = 'frtu'
        df_merged = merge_data(df_remote_sub,df_merged,flag)
        df_merged_add = add_value(df_merged)
        st.dataframe(df_merged_add)
        #df_ava_, peroid_name = add_peroid(df_merged_add, start_date, end_date)
        #st.dataframe(df_ava_)
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ CSV ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
        base_name = uploaded_file.name.rsplit('.', 1)[0]
        xlsx_filename = base_name + "_AVA" + ".xlsx"
        csv_filename = base_name + "_AVA" + ".csv"
        
        def to_excel(df):
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False, sheet_name='Sheet1')
            processed_data = output.getvalue()
            return processed_data
        
        excel_data = to_excel(df_merged_add)
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ xlsx,csv ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
        #xlsx_filename = 'availability_data' + '_' + peroid_name + ".xlsx"
        #csv_filename = 'availability_data' + '_' + peroid_name + ".csv"
        
        st.download_button(
            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î",
            data=excel_data,
            file_name=xlsx_filename,
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
            )

        df_export = df_merged_add.rename(columns={
            "Device": "‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå",
            "Description": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î",
            "Availability (%)": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (%)",
            "Availability Period": "‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
        })
        
        def to_csv(df):
            output = StringIO()
            df.to_csv(output, index=False, encoding='utf-8-sig', float_format="%.2f")  # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
            return output.getvalue()
        
        # ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô CSV text
        csv_data = to_csv(df_merged_add)
        # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV
        st.download_button(
            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (CSV)",
            data=csv_data,
            file_name=csv_filename,
            mime='text/csv'
        )
if __name__ == "__main__":
    main()
        
